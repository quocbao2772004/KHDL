{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8974b8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - /home/anonymous/code/KHDL/btl/web/backend/data/movie_index_new.csv\n",
      " - /home/anonymous/code/KHDL/btl/web/backend/data/movie_embeddings_new.npy\n",
      " - /home/anonymous/code/KHDL/btl/web/backend/data/tfidf_vectorizer.pkl\n",
      " - /home/anonymous/code/KHDL/btl/web/backend/data/X_tfidf_new.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "# ========= normalize helpers =========\n",
    "def norm_text(s: str) -> str:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = unidecode(s)\n",
    "    s = s.replace(\"_\", \" \").replace(\"-\", \" \")\n",
    "    s = re.sub(r\"[^a-z0-9\\s]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def parse_list_field(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(t) for t in x]\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            v = ast.literal_eval(s)\n",
    "            if isinstance(v, list):\n",
    "                return [str(t) for t in v]\n",
    "        except:\n",
    "            return []\n",
    "    return [s]\n",
    "\n",
    "def make_person_fields(name: str):\n",
    "    # trả 2 biến thể để match:\n",
    "    # \"rich lee\" và \"richlee\"\n",
    "    n = norm_text(name)\n",
    "    return n, n.replace(\" \", \"\")\n",
    "\n",
    "def build_search_text(row):\n",
    "    title = norm_text(row.get(\"title\", \"\"))\n",
    "    overview = norm_text(row.get(\"overview\", \"\"))\n",
    "\n",
    "    genres = \" \".join(norm_text(x) for x in parse_list_field(row.get(\"genres\", \"\")))\n",
    "    keywords = \" \".join(norm_text(x) for x in parse_list_field(row.get(\"keywords\", \"\")))\n",
    "\n",
    "    cast_list = parse_list_field(row.get(\"cast_top5\", \"\"))\n",
    "    cast_norms = []\n",
    "    cast_joins = []\n",
    "    for c in cast_list:\n",
    "        n, j = make_person_fields(c)\n",
    "        if n: cast_norms.append(n)\n",
    "        if j: cast_joins.append(j)\n",
    "\n",
    "    director = row.get(\"director\", \"\")\n",
    "    d_norm, d_join = make_person_fields(director)\n",
    "\n",
    "    # search_text để TFIDF/embedding\n",
    "    # nhét cả norm + join để user gõ \"richlee\" vẫn dính\n",
    "    parts = [\n",
    "        title,\n",
    "        genres,\n",
    "        keywords,\n",
    "        \" \".join(cast_norms),\n",
    "        \" \".join(cast_joins),\n",
    "        d_norm,\n",
    "        d_join,\n",
    "        overview\n",
    "    ]\n",
    "    return \" \".join([p for p in parts if p]).strip(), d_norm, d_join, cast_norms, cast_joins\n",
    "\n",
    "# ========= paths =========\n",
    "tmdb_csv = \"/home/anonymous/code/KHDL/btl/web/backend/data/tmdb_cleaned.csv\"\n",
    "out_dir  = \"/home/anonymous/code/KHDL/btl/web/backend/data\"\n",
    "\n",
    "out_index = os.path.join(out_dir, \"movie_index_new.csv\")\n",
    "out_emb   = os.path.join(out_dir, \"movie_embeddings_new.npy\")\n",
    "out_vec   = os.path.join(out_dir, \"tfidf_vectorizer.pkl\")\n",
    "out_xtfidf= os.path.join(out_dir, \"X_tfidf_new.npz\")\n",
    "\n",
    "# ========= load =========\n",
    "df = pd.read_csv(tmdb_csv)\n",
    "\n",
    "# build fields\n",
    "search_texts = []\n",
    "director_norms = []\n",
    "director_joins = []\n",
    "cast_norms_col = []\n",
    "cast_joins_col = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    stext, dnorm, djoin, cnorms, cjoins = build_search_text(row)\n",
    "    search_texts.append(stext)\n",
    "    director_norms.append(dnorm)\n",
    "    director_joins.append(djoin)\n",
    "    cast_norms_col.append(cnorms)\n",
    "    cast_joins_col.append(cjoins)\n",
    "\n",
    "df[\"search_text\"]   = search_texts\n",
    "df[\"director_norm\"] = director_norms\n",
    "df[\"director_join\"] = director_joins\n",
    "df[\"cast_norm\"]     = cast_norms_col\n",
    "df[\"cast_join\"]     = cast_joins_col\n",
    "df[\"title_norm\"]    = df[\"title\"].map(norm_text)\n",
    "\n",
    "# ========= TFIDF save =========\n",
    "tfidf = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=2)\n",
    "X = tfidf.fit_transform(df[\"search_text\"].fillna(\"\"))\n",
    "\n",
    "joblib.dump(tfidf, out_vec)\n",
    "sparse.save_npz(out_xtfidf, X)\n",
    "\n",
    "# ========= Embedding save =========\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "emb = model.encode(df[\"search_text\"].tolist(), convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "np.save(out_emb, emb)\n",
    "\n",
    "# ========= index save =========\n",
    "# lưu metadata cần cho UI + search\n",
    "keep_cols = [\n",
    "    \"tmdb_id\",\"title\",\"overview\",\"release_date\",\"genres\",\"runtime\",\n",
    "    \"vote_average\",\"vote_count\",\"popularity\",\"cast_top5\",\"director\",\"keywords\",\"poster_path\",\n",
    "    \"title_norm\",\"director_norm\",\"director_join\",\"cast_norm\",\"cast_join\"\n",
    "]\n",
    "keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "df[keep_cols].to_csv(out_index, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", out_index)\n",
    "print(\" -\", out_emb)\n",
    "print(\" -\", out_vec)\n",
    "print(\" -\", out_xtfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6ea4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_person_first(df, query, top_k=10):\n",
    "    qn = norm_text(query)\n",
    "    qj = qn.replace(\" \", \"\")\n",
    "\n",
    "    # 1) match director exact\n",
    "    m = (df[\"director_norm\"] == qn) | (df[\"director_join\"] == qj)\n",
    "    if m.any():\n",
    "        out = df[m].copy()\n",
    "        out[\"score\"] = 1.0\n",
    "        return out.sort_values([\"popularity\",\"vote_count\"], ascending=False).head(top_k)\n",
    "\n",
    "    # 2) match cast exact (cast_norm/cast_join là list)\n",
    "    def has_cast(row):\n",
    "        return (qn in row) or (qj in row)\n",
    "\n",
    "    m2 = df[\"cast_norm\"].apply(has_cast) | df[\"cast_join\"].apply(has_cast)\n",
    "    if m2.any():\n",
    "        out = df[m2].copy()\n",
    "        out[\"score\"] = 0.9\n",
    "        return out.sort_values([\"popularity\",\"vote_count\"], ascending=False).head(top_k)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9f48b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def norm_text(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = s.strip().lower()\n",
    "    s = unidecode(s)\n",
    "    s = s.replace(\"_\", \" \").replace(\"-\", \" \")\n",
    "    s = re.sub(r\"[^a-z0-9\\s]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def director_exact_boost(idx_df, query, top_k=10):\n",
    "    qn = norm_text(query)\n",
    "    qj = qn.replace(\" \", \"\")\n",
    "\n",
    "    # director raw -> norm/join\n",
    "    d_norm = idx_df[\"director\"].astype(str).map(norm_text)\n",
    "    d_join = d_norm.str.replace(\" \", \"\", regex=False)\n",
    "\n",
    "    m = (d_norm == qn) | (d_join == qj)\n",
    "    out = idx_df[m].copy()\n",
    "    if len(out) == 0:\n",
    "        return None\n",
    "\n",
    "    out[\"score\"] = 1.0\n",
    "    return out[[\"tmdb_id\",\"title\",\"director\",\"score\"]].head(top_k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
