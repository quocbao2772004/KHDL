{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6201535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    science_fiction adventure fantasy witch clone ...\n",
      "1    action mystery drama based_on_novel_or_book le...\n",
      "2    animation comedy adventure family mystery snak...\n",
      "Name: bert_text, dtype: object\n",
      "Empty bert_text: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/home/anonymous/code/KHDL/btl/data/tmdb_cleaned.csv\")\n",
    "\n",
    "def to_list(x):\n",
    "    \"\"\"Đảm bảo output là list[str]\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(i) for i in x if pd.notna(i)]\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        # nếu là string dạng list: \"['a','b']\"\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                v = ast.literal_eval(s)\n",
    "                if isinstance(v, list):\n",
    "                    return [str(i) for i in v if pd.notna(i)]\n",
    "            except:\n",
    "                pass\n",
    "        # nếu là chuỗi thường, coi như 1 token\n",
    "        return [s]\n",
    "    # số/float -> bỏ hoặc cast\n",
    "    return []\n",
    "\n",
    "def to_text(x):\n",
    "    \"\"\"Đảm bảo output là str\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x)\n",
    "\n",
    "# Chuẩn hóa 3 cột list\n",
    "for col in [\"genres\", \"keywords\", \"cast_top5\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(to_list)\n",
    "    else:\n",
    "        df[col] = [[]]*len(df)\n",
    "\n",
    "# Chuẩn hóa text\n",
    "df[\"director\"] = df[\"director\"].apply(to_text)\n",
    "df[\"overview\"] = df[\"overview\"].apply(to_text)\n",
    "\n",
    "def make_text(row):\n",
    "    return (\n",
    "        \" \".join(row[\"genres\"]) + \" \" +\n",
    "        \" \".join(row[\"keywords\"]) + \" \" +\n",
    "        \" \".join(row[\"cast_top5\"]) + \" \" +\n",
    "        row[\"director\"] + \" \" +\n",
    "        row[\"overview\"]\n",
    "    ).strip()\n",
    "\n",
    "df[\"bert_text\"] = df.apply(make_text, axis=1)\n",
    "\n",
    "print(df[\"bert_text\"].head(3))\n",
    "print(\"Empty bert_text:\", (df[\"bert_text\"].str.len() == 0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d59fe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f63be4824b49778985dcd6a4b647d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a552052ff8e4f41b47c8f092e4f99a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2de2770cb14b268bbfe37e48d62730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f118f727744a0b92e6fb0a855760b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ebed4aa8be41a4ab83b893afb345b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f4c14e948740d6ae021976bdd2a035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7966fe661cac4b2cb974cc18984adebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7ce939d8a94446a8c03bc123e052f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4b9931d1b44bfda851fdb063bfc5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12482313a84c4c049cdb2309e0cbcf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c366f1ed2af4dc287789861da16281f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1c29125b664208add9ea8ac958eab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: movie_embeddings.npy + movie_index.csv\n",
      "Embeddings shape: (2173, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# df đang có cột bert_text từ bước trước\n",
    "texts = df[\"bert_text\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True  # quan trọng: giúp cosine similarity nhanh & ổn hơn\n",
    ")\n",
    "\n",
    "# lưu để lần sau khỏi encode lại\n",
    "np.save(\"movie_embeddings.npy\", embeddings)\n",
    "\n",
    "# lưu index (cần title + tmdb_id + poster_path nếu có)\n",
    "keep_cols = [\"tmdb_id\", \"title\"]\n",
    "if \"poster_path\" in df.columns:\n",
    "    keep_cols.append(\"poster_path\")\n",
    "\n",
    "df[keep_cols].to_csv(\"movie_index.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved: movie_embeddings.npy + movie_index.csv\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2935bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tmdb_id                 title                       poster_path     score\n",
      "0  1386827               Coyotes  /fSzs9ZXYcrln0FRrjGIPCjuB6En.jpg  0.658136\n",
      "1    34851             Predators  /wdniP8NDaJIydi1hMxhpbJMUfr6.jpg  0.644610\n",
      "2   629542          The Bad Guys  /6fcFmdVLCCbf1gFt8HlC6BRj8pt.jpg  0.632682\n",
      "3    10730             King Kong  /paYKhEwUaxKA05vmOfU7FlleTln.jpg  0.628121\n",
      "4      869    Planet of the Apes  /eEsOgbgKXMvI2FEw1WENamVXi41.jpg  0.610657\n",
      "5  1175942        The Bad Guys 2  /c1msaKf1wyuKcmLjjJd6rIBPFcd.jpg  0.606672\n",
      "6      106              Predator  /k3mW4qfJo6SKqe6laRyNGnbB9n5.jpg  0.604366\n",
      "7     4247           Scary Movie  /fVQFPRuw3yWXojYDJvA5EoFjUOY.jpg  0.602479\n",
      "8  1196364                Thamma  /udkbDwBbysCGEydt0FHnl9dVO2k.jpg  0.598963\n",
      "9  1049942  Bambi: The Reckoning  /8oBbWxWDJrrDtNkmd0OzZpPFFUR.jpg  0.595286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "idx_df = pd.read_csv(\"movie_index.csv\")\n",
    "emb = np.load(\"movie_embeddings.npy\")\n",
    "\n",
    "# map title -> index (lowercase)\n",
    "title_to_idx = pd.Series(idx_df.index, index=idx_df[\"title\"].astype(str).str.lower()).drop_duplicates()\n",
    "\n",
    "def recommend_by_title(title, top_k=10):\n",
    "    key = str(title).strip().lower()\n",
    "    if key not in title_to_idx:\n",
    "        # gợi ý gần đúng\n",
    "        cand = idx_df[idx_df[\"title\"].str.lower().str.contains(key, na=False)][\"title\"].head(10).tolist()\n",
    "        raise ValueError(f\"Không tìm thấy title chính xác. Gợi ý gần giống: {cand}\")\n",
    "\n",
    "    q = int(title_to_idx[key])\n",
    "\n",
    "    # vì embeddings đã normalize -> cosine = dot product\n",
    "    sims = emb @ emb[q]   # (N,)\n",
    "    # lấy top_k + 1 để bỏ chính nó\n",
    "    top_idx = np.argsort(sims)[::-1][:top_k+1]\n",
    "\n",
    "    # bỏ chính nó\n",
    "    top_idx = [i for i in top_idx if i != q][:top_k]\n",
    "\n",
    "    rec = idx_df.iloc[top_idx].copy()\n",
    "    rec[\"score\"] = sims[top_idx]\n",
    "    return rec.reset_index(drop=True)\n",
    "\n",
    "print(recommend_by_title(\"Anaconda\", top_k=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca2d72a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Avatar', 90.0, 30), ('Avatar: Fire and Ash', 87.17948717948718, 0), (\"Harry Potter and the Philosopher's Stone\", 85.5, 129), ('The Chronicles of Narnia: The Lion, the Witch and the Wardrobe', 85.5, 146), ('Avatar 4', 85.5, 203), ('Harry Potter and the Chamber of Secrets', 85.5, 221), ('Harry Potter and the Goblet of Fire', 85.5, 222), ('Harry Potter and the Order of the Phoenix', 85.5, 227), ('Captain Sabertooth and the Countess of Grel', 85.5, 237), ('Harry Potter and the Prisoner of Azkaban', 85.5, 278)]\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def find_title_close(query, top_n=10):\n",
    "    titles = idx_df[\"title\"].astype(str).tolist()\n",
    "    matches = process.extract(query, titles, scorer=fuzz.WRatio, limit=top_n)\n",
    "    # trả về list (title, score)\n",
    "    return matches\n",
    "\n",
    "print(find_title_close(\"Avatar fire and ash\", top_n=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbcf5397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tmdb_id                                              title  \\\n",
      "0   976573                                          Elemental   \n",
      "1    83533                               Avatar: Fire and Ash   \n",
      "2   393209                                           Avatar 5   \n",
      "3   216527                                           Avatar 4   \n",
      "4       81                 Nausicaä of the Valley of the Wind   \n",
      "5      128                                  Princess Mononoke   \n",
      "6   635302  Demon Slayer -Kimetsu no Yaiba- The Movie: Mug...   \n",
      "7    12222                                Horton Hears a Who!   \n",
      "8    25961                       Pokémon: The Rise of Darkrai   \n",
      "9    11688                           The Emperor's New Groove   \n",
      "\n",
      "                        poster_path     score  \n",
      "0  /4Y1WNkd88JXmGfhtWR7dmDAo1T2.jpg  0.485050  \n",
      "1  /g96wHxU7EnoIFwemb2RgohIXrgW.jpg  0.474995  \n",
      "2  /rtmmvqkIC5zDMEd638Es2woxbz8.jpg  0.459310  \n",
      "3  /qzMYKnT4MG1d0gnhwytr4cKhUvS.jpg  0.451863  \n",
      "4  /tcrkfB8SRPQCgwI88hQScua6nxh.jpg  0.442857  \n",
      "5  /cMYCDADoLKLbB83g4WnJegaZimC.jpg  0.434893  \n",
      "6  /h8Rb9gBr48ODIwYUttZNYeMWeUU.jpg  0.431186  \n",
      "7  /6k47Z3A5zI2rxubTMwiLyIqQLLr.jpg  0.419654  \n",
      "8  /yElGG6lxLtQXcgBVzF7Xxq7YRa2.jpg  0.416300  \n",
      "9  /wwbgkXQBEKtnyIJapk6gUgWkVw8.jpg  0.407863  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# load model đúng cái mày đã dùng để encode\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def recommend_by_query_text(query, top_k=10):\n",
    "    q_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    sims = emb @ q_emb\n",
    "    top_idx = np.argsort(sims)[::-1][:top_k]\n",
    "    rec = idx_df.iloc[top_idx].copy()\n",
    "    rec[\"score\"] = sims[top_idx]\n",
    "    return rec.reset_index(drop=True)\n",
    "\n",
    "print(recommend_by_query_text(\"Avatar fire and ash\", top_k=10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
