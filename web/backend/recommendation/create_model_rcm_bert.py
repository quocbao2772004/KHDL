# -*- coding: utf-8 -*-
"""rcm_bert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wGgusF2vhed7X67YLaReuUFQWy8Z0g8l
"""

import pandas as pd
import ast
import numpy as np

df = pd.read_csv("/home/anonymous/code/KHDL/btl/data/tmdb_cleaned.csv")

def to_list(x):
    """Đảm bảo output là list[str]"""
    if pd.isna(x):
        return []
    if isinstance(x, list):
        return [str(i) for i in x if pd.notna(i)]
    if isinstance(x, str):
        s = x.strip()
        # nếu là string dạng list: "['a','b']"
        if s.startswith("[") and s.endswith("]"):
            try:
                v = ast.literal_eval(s)
                if isinstance(v, list):
                    return [str(i) for i in v if pd.notna(i)]
            except:
                pass
        # nếu là chuỗi thường, coi như 1 token
        return [s]
    # số/float -> bỏ hoặc cast
    return []

def to_text(x):
    """Đảm bảo output là str"""
    if pd.isna(x):
        return ""
    return str(x)

# Chuẩn hóa 3 cột list
for col in ["genres", "keywords", "cast_top5"]:
    if col in df.columns:
        df[col] = df[col].apply(to_list)
    else:
        df[col] = [[]]*len(df)

# Chuẩn hóa text
df["director"] = df["director"].apply(to_text)
df["overview"] = df["overview"].apply(to_text)

def make_text(row):
    return (
        " ".join(row["genres"]) + " " +
        " ".join(row["keywords"]) + " " +
        " ".join(row["cast_top5"]) + " " +
        row["director"] + " " +
        row["overview"]
    ).strip()

df["bert_text"] = df.apply(make_text, axis=1)

print(df["bert_text"].head(3))
print("Empty bert_text:", (df["bert_text"].str.len() == 0).sum())

import numpy as np
from sentence_transformers import SentenceTransformer

# df đang có cột bert_text từ bước trước
texts = df["bert_text"].fillna("").astype(str).tolist()

model = SentenceTransformer("all-MiniLM-L6-v2")

embeddings = model.encode(
    texts,
    show_progress_bar=True,
    convert_to_numpy=True,
    normalize_embeddings=True  # quan trọng: giúp cosine similarity nhanh & ổn hơn
)

# lưu để lần sau khỏi encode lại
np.save("movie_embeddings.npy", embeddings)

# lưu index (cần title + tmdb_id + poster_path nếu có)
keep_cols = ["tmdb_id", "title"]
if "poster_path" in df.columns:
    keep_cols.append("poster_path")

df[keep_cols].to_csv("movie_index.csv", index=False, encoding="utf-8-sig")

print("Saved: movie_embeddings.npy + movie_index.csv")
print("Embeddings shape:", embeddings.shape)

import pandas as pd
import numpy as np

idx_df = pd.read_csv("movie_index.csv")
emb = np.load("movie_embeddings.npy")

# map title -> index (lowercase)
title_to_idx = pd.Series(idx_df.index, index=idx_df["title"].astype(str).str.lower()).drop_duplicates()

def recommend_by_title(title, top_k=10):
    key = str(title).strip().lower()
    if key not in title_to_idx:
        # gợi ý gần đúng
        cand = idx_df[idx_df["title"].str.lower().str.contains(key, na=False)]["title"].head(10).tolist()
        raise ValueError(f"Không tìm thấy title chính xác. Gợi ý gần giống: {cand}")

    q = int(title_to_idx[key])

    # vì embeddings đã normalize -> cosine = dot product
    sims = emb @ emb[q]   # (N,)
    # lấy top_k + 1 để bỏ chính nó
    top_idx = np.argsort(sims)[::-1][:top_k+1]

    # bỏ chính nó
    top_idx = [i for i in top_idx if i != q][:top_k]

    rec = idx_df.iloc[top_idx].copy()
    rec["score"] = sims[top_idx]
    return rec.reset_index(drop=True)

print(recommend_by_title("Anaconda", top_k=10))

from rapidfuzz import process, fuzz

def find_title_close(query, top_n=10):
    titles = idx_df["title"].astype(str).tolist()
    matches = process.extract(query, titles, scorer=fuzz.WRatio, limit=top_n)
    # trả về list (title, score)
    return matches

print(find_title_close("Avatar fire and ash", top_n=10))

from sentence_transformers import SentenceTransformer
import numpy as np

# load model đúng cái mày đã dùng để encode
model = SentenceTransformer("all-MiniLM-L6-v2")

def recommend_by_query_text(query, top_k=10):
    q_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]
    sims = emb @ q_emb
    top_idx = np.argsort(sims)[::-1][:top_k]
    rec = idx_df.iloc[top_idx].copy()
    rec["score"] = sims[top_idx]
    return rec.reset_index(drop=True)

print(recommend_by_query_text("Avatar fire and ash", top_k=10))